{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the observed dataset\n",
    "input_data = pd.read_csv('RL_input.csv')\n",
    "ob_data = input_data.groupby('ObservedID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link \n",
    "link = {1: [1, 3],\n",
    "        2: [2, 5],\n",
    "        3: [3, 4], \n",
    "        4: [5, 8],\n",
    "        5: [4, 9],\n",
    "        6: [7, 10],\n",
    "        7: [8, 11],\n",
    "        8: [9, 12],\n",
    "        9: [10, 13],\n",
    "       10: [11, 14],\n",
    "       11: [12, 15],\n",
    "       12: [3, 6],\n",
    "       13: [5, 4],\n",
    "       14: [4, 7],\n",
    "       15: [8, 9],\n",
    "       16: [9, 10],\n",
    "       17: [11, 12],\n",
    "       18: [12, 13],\n",
    "       19: [11, 15],\n",
    "       20: [14, 15],\n",
    "       21: [6, 16],\n",
    "       22: [7, 16],\n",
    "       23: [16, 10],\n",
    "       24: [16, 17],\n",
    "       25: [16, 17],\n",
    "       26: [10, 17],\n",
    "       27: [13, 17],\n",
    "       28: [12, 17],\n",
    "       29: [15, 17]}\n",
    "\n",
    "# network nodes\n",
    "node = {17: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "        16: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "        15: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "        14: tf.Variable([0.0, ], dtype=tf.float32),    \n",
    "        13: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "        12: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "        11: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "        10: tf.Variable([0.0, ], dtype=tf.float32),    \n",
    "         9: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "         8: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "         7: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "         6: tf.Variable([0.0, ], dtype=tf.float32),   \n",
    "         5: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "         4: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "         3: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "         2: tf.Variable([0.0, ], dtype=tf.float32), \n",
    "         1: tf.Variable([0.0, ], dtype=tf.float32)}\n",
    "\n",
    "# Define Parameters (initial values)\n",
    "travel_time = tf.Variable([-1.5, ], dtype=tf.float32, name='travel_time')\n",
    "travel_sign = tf.Variable([-1.5,], dtype=tf.float32, name='travel_signal')\n",
    "link_const = tf.Variable([-1.5, ], dtype=tf.float32, name='travel_constant')\n",
    "\n",
    "param_val = [travel_time, travel_sign, link_const]\n",
    "\n",
    "# Three attributes (travel time, travel_sign, link_const)\n",
    "utility = {\n",
    "            1:  [1, 0, 1],\n",
    "            2:  [1, 0, 1],\n",
    "            3:  [1.5, 1, 1],\n",
    "            4:  [1.2, 0, 1],\n",
    "            5:  [1.2, 1, 1],\n",
    "            6:  [1.2, 1, 1],\n",
    "            7:  [1.1,0, 1],\n",
    "            8:  [1,  1, 1],\n",
    "            9:  [1.2, 0, 1],\n",
    "           10:  [0.5, 0, 1],\n",
    "           11:  [0.5, 0, 1],\n",
    "           12:  [1, 0, 1],\n",
    "           13:  [1, 1, 1],\n",
    "           14:  [1, 1, 1],\n",
    "           15:  [1, 1, 1],\n",
    "           16:  [1, 1, 1],\n",
    "           17:  [0.8, 1,1],\n",
    "           18:  [1.4, 0,1],\n",
    "           19:  [0.9, 0,1],\n",
    "           20:  [0.8, 0,1],\n",
    "           21:  [2.1, 0,1],\n",
    "           22:  [0.9, 0,1],\n",
    "           23:  [1.7, 0, 1],\n",
    "           24:  [5.3, 0, 1],\n",
    "           25:  [4.5, 0, 1],\n",
    "           26:  [3, 0, 1],\n",
    "           27:  [2.5, 0, 1],\n",
    "           28:  [3.3, 0, 1],\n",
    "           29:  [3, 0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fun(node, link, utility, param_val):\n",
    "    \n",
    "    # update the utility using three attributes with parameters\n",
    "    up_utility = {}\n",
    "    for p in range(len(utility)):\n",
    "        \n",
    "        up_utility[p+1] = param_val[0]*utility[p+1][0]+ param_val[1]*utility[p+1][1]+ param_val[2]*utility[p+1][2]\n",
    "    \n",
    "    # loop for computing the value functions \n",
    "    '''TO DO: optimize the calculation'''\n",
    "    for i in node:\n",
    "        # find the matched links\n",
    "        a = [key for key, values in link.items() if link[key][0] == i]\n",
    "        \n",
    "        if a==[]:\n",
    "            node[i] = tf.constant(0, dtype=tf.float32)\n",
    "\n",
    "        if a!=[]:\n",
    "            outnode = []\n",
    "            sum_exp = tf.constant([0], dtype=tf.float32)\n",
    "            for j in range(len(a)):\n",
    "                # find the \"tonode\"\n",
    "                outnode = np.append(outnode, link[a[j]][1])\n",
    "                \n",
    "                # calculate the exponential function\n",
    "                exp_cal = tf.math.exp(tf.math.add(-up_utility[a[j]], node[outnode[j]]))\n",
    "                exp_cal = tf.reshape(exp_cal, shape=[1, ])\n",
    "\n",
    "                sum_exp = tf.concat([sum_exp, exp_cal], 0)\n",
    "\n",
    "            node[i] = tf.math.log(tf.reduce_sum(sum_exp))\n",
    "    \n",
    "    up_node = node\n",
    "    up_utility = up_utility\n",
    "    \n",
    "    link_prob = {}\n",
    "    \n",
    "    # Loop for calculating probabilities of each link\n",
    "    for k in link:\n",
    "\n",
    "        # find the matched links\n",
    "        b = [key for key, values in link.items() if link[key][0] == k]\n",
    "\n",
    "        if b==[]:\n",
    "            break\n",
    "        outnode = []\n",
    "        exp_inv = tf.constant([0], dtype=tf.float32)\n",
    "\n",
    "        # To compute each exponential function\n",
    "        for p in range(len(b)):\n",
    "            # find the \"tonode\"\n",
    "            outnode = np.append(outnode, link[b[p]][1])\n",
    "            # calculate the exponential function\n",
    "            exp_cal = tf.math.exp(tf.math.add(-up_utility[b[p]], up_node[outnode[p]]))\n",
    "            exp_cal = tf.reshape(exp_cal, shape=[1, ])\n",
    "            exp_inv = tf.concat([exp_inv, exp_cal], 0)\n",
    "\n",
    "        # To store probabilities of each link\n",
    "        for t in range(len(b)):\n",
    "\n",
    "            link_prob[b[t]] = exp_inv[t+1]/(tf.reduce_sum(exp_inv)) \n",
    "            \n",
    "    return link_prob\n",
    "\n",
    "def cost_func(ob_data, yhat):\n",
    "    \n",
    "    total_choice = tf.constant([0], dtype=tf.float32)\n",
    "\n",
    "    for i in range(len(ob_data)):\n",
    "\n",
    "        obs = ob_data.get_group(i+1).sequence.values\n",
    "\n",
    "        path_choice = tf.constant([1], dtype=tf.float32)\n",
    "        \n",
    "        for h in obs:\n",
    "\n",
    "            path_choice = tf.math.multiply(yhat[h], path_choice)\n",
    "\n",
    "        total_choice = tf.concat([total_choice, path_choice], 0)\n",
    "        \n",
    "    est_cost = total_choice[1:]\n",
    "    \n",
    "    return -tf.reduce_sum(tf.math.log(est_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain the shapes of all trainable parameters in the model\n",
    "def LL_gradient(node, link, utility, ob_data, param_val):\n",
    "    model_fun(node, link, utility, param_val)\n",
    "    shapes = tf.shape_n(param_val)\n",
    "    n_tensors = len(shapes)\n",
    "    \n",
    "    count = 0\n",
    "    idx =  [] \n",
    "    part = []\n",
    "    \n",
    "    for i, shape in enumerate(shapes):\n",
    "        n = numpy.product(shape)\n",
    "        idx.append(tf.reshape(tf.range(count, count+n, dtype=tf.int32), shape))\n",
    "        part.extend([i]*n)\n",
    "        count += n\n",
    "        \n",
    "    @tf.function\n",
    "    def assign_new_model_parameters(params_1d):\n",
    "\n",
    "        updated_params = tf.dynamic_partition(params_1d, part, n_tensors)\n",
    "        \n",
    "        for i, (shape, param) in enumerate(zip(shapes, updated_params)):\n",
    "            param_val[i].assign(tf.reshape(param, shape))\n",
    "                   \n",
    "    @tf.function \n",
    "    def est_grad(params_1d):\n",
    "        \n",
    "        # Derive the Tensorflow gradient\n",
    "        with tf.GradientTape(persistent=True) as tape: \n",
    "            \n",
    "            # Call the function to update and convert the shape of parameters\n",
    "            \n",
    "            assign_new_model_parameters(params_1d)\n",
    "            \n",
    "            # Call the cost function\n",
    "            \n",
    "            yhat = model_fun(node, link, utility, param_val)\n",
    "            \n",
    "            loss_value = cost_func(ob_data, yhat)\n",
    "            \n",
    "        estimated_grad = tape.gradient(loss_value, param_val)\n",
    "        grads_1dim = tf.dynamic_stitch(idx, estimated_grad)\n",
    "        return loss_value, grads_1dim\n",
    "    \n",
    "    est_grad.idx = idx\n",
    "    \n",
    "    return est_grad\n",
    "\n",
    "# Define the positions of initial parameters\n",
    "init_params = tf.dynamic_stitch(LL_gradient(node, link, utility, ob_data, param_val).idx, param_val)\n",
    "\n",
    "# Implement the BFGS optimizer\n",
    "Trained_Results = tfp.optimizer.bfgs_minimize(\n",
    "                                      value_and_gradients_function=LL_gradient(node, link, utility, ob_data, param_val), \n",
    "                                      initial_position=init_params,\n",
    "                                      tolerance=1e-08,\n",
    "                                      max_iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'travel_time:0' shape=(1,) dtype=float32, numpy=array([16.659325], dtype=float32)>,\n",
       " <tf.Variable 'travel_signal:0' shape=(1,) dtype=float32, numpy=array([48.786137], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
